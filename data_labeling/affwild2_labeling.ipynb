{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "affwild2_labeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcafarelli/CMT-ABAW2020-EXPR/blob/main/affwild2_labeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ogWSL68zCfE"
      },
      "source": [
        "This notebook will bind a label to the corresponding frame. It will return two pandas dataframes in the form of frame_path/label for the train and validation set.\n",
        "\n",
        "Download cropped aligned files and annotations from the competition and \n",
        "- set train files dir\n",
        "- set validation files dir\n",
        "- set annotations dir "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZbBij9prN0w"
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import glob\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import csv\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx-HOgWguO3Y"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaTLz_ltuZYg"
      },
      "source": [
        "#!unzip '/content/gdrive/My Drive/TESI/FER/AffWild2/cropped_aligned_train.zip' -d '/content/cropped_aligned_train/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IbmzLbjuhIx"
      },
      "source": [
        "#!unzip '/content/gdrive/MyDrive/TESI/FER/AffWild2/cropped_aligned/cropped_aligned_val.zip' -d '/content/cropped_aligned_val/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knrlmTT7wEEX"
      },
      "source": [
        "# --------- PATHS ---------\n",
        "\n",
        "annot_dir = '/content/gdrive/My Drive/TESI/FER/AffWild2/annotations'\n",
        "train_set_dir = '/content/cropped_aligned_train/'\n",
        "validation_set_dir = '/content/cropped_aligned_val/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EMj-uHgrN07"
      },
      "source": [
        "def read_Expr(txt_file):\n",
        "    with open(txt_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    lines = lines[1:] # skip first line\n",
        "    lines = [x.strip() for x in lines]\n",
        "    lines = [int(x) for x in lines]\n",
        "    return np.array(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y_NqanJrN1F"
      },
      "source": [
        "def frames_to_label(name,label_array, frames, discard_value):\n",
        "    try:\n",
        "        assert len(label_array) >= len(frames) # some labels need to be discarded\n",
        "    except AssertionError:\n",
        "        print('Houston, we have a problem. Lab array > frames')\n",
        "        print(name)\n",
        "        pass\n",
        "        \n",
        "    frames_ids = [int(frame.split('/')[-1].split('.')[0]) - 1 for frame in frames] # frame_id start from 0\n",
        "    N = label_array.shape[0]\n",
        "    label_array = label_array.reshape((N, -1))\n",
        "    to_drop = (label_array == discard_value).sum(-1)\n",
        "    drop_ids = [i for i in range(len(to_drop)) if to_drop[i]]\n",
        "    frames_ids = [i for i in frames_ids if i not in drop_ids]\n",
        "    indexes = [True if i in frames_ids else False for i in range(len(label_array)) ]\n",
        "    label_array = label_array[indexes]\n",
        "    try:\n",
        "        assert len(label_array) == len(frames_ids)\n",
        "    except AssertionError:\n",
        "        print('Houston, we have a problem.')\n",
        "        print(name)\n",
        "        pass\n",
        "    try:\n",
        "        prefix = '/'.join(name)\n",
        "        #prefix = os.path.join('/', frames[34:])\n",
        "    except IndexError:\n",
        "        prefix = 'null'\n",
        "        print('Exc: ',frames )\n",
        "    return_frames = ['/'+name+'/{0:05d}.jpg'.format(id+1) for id in frames_ids]\n",
        "    return label_array, return_frames, frames_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNKJLjyhrN1f"
      },
      "source": [
        "def create_annotations_dict(mode, path):\n",
        "  tasks = [x for x in os.listdir(annot_dir)]\n",
        "  data_file = {}\n",
        "  for task in tasks:\n",
        "      if task == 'EXPR_Set':\n",
        "          Expr_list = ['Neutral','Anger','Disgust','Fear','Happiness','Sadness','Surprise']\n",
        "          data_file[task] ={}\n",
        "          for mode in [mode]:\n",
        "          #data_file[mode] = {}\n",
        "              txt_files = glob.glob(os.path.join(annot_dir, task, mode, '*.txt'))\n",
        "              data_file[task][mode] = {}\n",
        "              for txt_file in tqdm(txt_files):\n",
        "                  name = os.path.basename(txt_file).split('.')[0]\n",
        "                  print(\"Folder Name\", name)\n",
        "                  expr_array = read_Expr(txt_file)\n",
        "                  #frames_paths = sorted(glob.glob(os.path.join('/content', mode, name, '*.jpg')))\n",
        "                  frames_paths = sorted(glob.glob(os.path.join(path, name, '*.jpg')))\n",
        "                  #print(frames_paths)\n",
        "                  expr_array, frames_paths, frames_ids = frames_to_label(name,expr_array, frames_paths, discard_value = -1)\n",
        "                  data_dict = {'path':frames_paths, 'label':expr_array.reshape(-1) }\n",
        "                  print(len(frames_paths), len(expr_array))\n",
        "                  data_file[name] = pd.DataFrame.from_dict(data_dict)\n",
        "  return data_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGLm0WJ8GmYO"
      },
      "source": [
        "#Training Set\n",
        "data_file_train = create_annotations_dict('Training_Set', train_set_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWqzLH944q_n"
      },
      "source": [
        "#Validation Set\n",
        "data_file_val = create_annotations_dict('Validation_Set', validation_set_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7ZULiyA97vN"
      },
      "source": [
        "# Create Pandas DataFrame TRAIN SET\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh8551HerN1j"
      },
      "source": [
        "train_set = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDJpDOyirN1l"
      },
      "source": [
        "txt_files = glob.glob(os.path.join(annot_dir,'EXPR_Set', 'Training_Set', '*.txt'))\n",
        "for i, txt_file in tqdm(enumerate(txt_files)):\n",
        "    name = os.path.basename(txt_file).split('.')[0]\n",
        "    data = data_file_train[name]\n",
        "    test_set = test_set.append(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y85_TKyrN1o"
      },
      "source": [
        "histogram = train_set['label'].hist(bins = train_set['label'].nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJV0S6K97Wxn"
      },
      "source": [
        "print(train_set['label'].value_counts(normalize=True) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXUtO3fyrN1q"
      },
      "source": [
        "print(train_set['label'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcqyBTuTrN1t"
      },
      "source": [
        "save_path = os.path.join(annot_dir, 'train_set.pkl')\n",
        "print(save_path)\n",
        "train_set.to_pickle(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbPF5Pj8-I07"
      },
      "source": [
        "# Create Pandas DataFrame VALIDATION SET\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4nrOu32rN10"
      },
      "source": [
        "val_set = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em3LmLByrN11"
      },
      "source": [
        "txt_files = glob.glob(os.path.join(annot_dir, 'EXPR_Set', 'Validation_Set', '*.txt'))\n",
        "\n",
        "for i, txt_file in tqdm(enumerate(txt_files)):\n",
        "    name = os.path.basename(txt_file).split('.')[0]\n",
        "    data = data_file_val[name]\n",
        "    val_set = val_set.append(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "779bnIF5AFIC"
      },
      "source": [
        "val_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCg-czoum299"
      },
      "source": [
        "print(val_set.label.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVt_c4CQrN16"
      },
      "source": [
        "histogram_val = val_set['label'].hist(bins = val_set['label'].nunique())\n",
        "print(val_set['label'].value_counts())\n",
        "print(val_set['label'].value_counts(normalize=True) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD8QTxaRBP_J"
      },
      "source": [
        "save_path = os.path.join(annot_dir, 'val_set.pkl')\n",
        "print(save_path)\n",
        "val_set.to_pickle(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
