{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi_resolution_validation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcafarelli/CMT-ABAW2020-EXPR/blob/main/test/multi_resolution_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTq6kVjdtaep"
      },
      "source": [
        "!pip install confplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QwKIEdxuDc9"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import sys\n",
        "from fastprogress.fastprogress import master_bar, progress_bar\n",
        "import sklearn.metrics as sm\n",
        "import confplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__W4b1CUKr51"
      },
      "source": [
        "validation_dir = '/cropped_aligned_val/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySo7Tm-GLQeW"
      },
      "source": [
        "#CUDA FOR PYTORCH\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True #This flag allows you to enable the inbuilt cudnn auto-tuner to find the best algorithm to use for your hardware.\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIIHwWrPkcgb"
      },
      "source": [
        "classes = ('Neutral', 'Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise')\n",
        "classes_nt = ('Neutral', 'Positive', 'Negative')\n",
        "\n",
        "val_df_nt_path = '/annotations/three_classes_val_label.pkl' #path to 3 classes validation set\n",
        "val_df_path = '/annotations/val_set.pkl' #path to affwild2 validation set\n",
        "\n",
        "path_best_model = '/best_performance_model/best_model-senet50-0.43.pt' #model 7 classes\n",
        "\n",
        "#-------- models below work only on 3 classes set -----------\n",
        "#path_best_model = '/best_performance_model/best_model_sen50_newtask.pt' #standard train/base model\n",
        "#path_best_model= '/best_performance_model/best_multi-res-train_newtask3920_unbalanced_0612.pt' #multi-res train/multi-res model\n",
        "#path_best_model = '/best_performance_model/best_multi-res-train_newtask_unbalanced-basemodel.pt' #multi-res train/base model\n",
        "\n",
        "#--------- ckp path to load the model ---------\n",
        "model_base_path_colab = '/model_checkpoint/pytorch_models/senet50_ft_pytorch.pth'\n",
        "model_ckp_path = '/model_checkpoint/pytorch_models/models_ckp_78561.pth.tar' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEBXjSiDlnqF"
      },
      "source": [
        "# LOAD BEST MODEL SENET50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mmaK86Kl9eI"
      },
      "source": [
        "sys.path.append('/path/where/MainModel.py/is_located') #append the path where MainModel.py is located\n",
        "import MainModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peVQjClrXNZb"
      },
      "source": [
        "def load_models(model_base_path, device=\"cpu\", model_ckp=None):\n",
        "    assert os.path.exists(model_base_path), \"Base model checkpoint not found at: {}\".format(model_base_path)\n",
        "    model = torch.load(model_base_path)\n",
        "    if model_ckp is not None:\n",
        "        assert os.path.exists(model_ckp), f\"Model checkpoint not found at: {model_ckp}\"\n",
        "        ckp = torch.load(model_ckp, map_location='cpu')\n",
        "        [p.data.copy_(torch.from_numpy(ckp['model_state_dict'][n].numpy())) for n, p in model.named_parameters()]\n",
        "        for n, m in model.named_modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.momentum = 0.1\n",
        "                m.running_var = ckp['model_state_dict'][n + '.running_var']\n",
        "                m.running_mean = ckp['model_state_dict'][n + '.running_mean']\n",
        "                m.num_batches_tracked = ckp['model_state_dict'][n + '.num_batches_tracked']\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da52B6GymDvE"
      },
      "source": [
        "model = load_models(model_base_path_colab, device, None)\n",
        "\n",
        "for k, m in model.named_modules():\n",
        "  m._non_persistent_buffers_set = set()  # pytorch 1.6.0 compatability"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhstbA5j0NFX"
      },
      "source": [
        "def reshape(flag, model):\n",
        "  if flag == \"affwild2\":\n",
        "    model.classifier_1 = nn.Linear(2048, len(classes))\n",
        "  else \n",
        "    model.classifier_1 = nn.Linear(2048, len(classes_nt))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL4fEt9SfkIs"
      },
      "source": [
        "model = reshape(\"affwild2\", model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYrNcQmkmQyz"
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzZY01ZVmolj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca17a552-eb7d-4f72-c4de-7e09b8ecb485"
      },
      "source": [
        "#Load state dict\n",
        "ckp = torch.load(path_best_model)\n",
        "model.load_state_dict(ckp['state_dict'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPcLLHO9CzXq"
      },
      "source": [
        "# VALIDATION ON DIFFERENT IMAGE RESOLUTION\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEsC16whC31V"
      },
      "source": [
        "class AffWild2ValSet(Dataset):\n",
        "    def __init__(self, choose_set, transform=None, res=None):\n",
        "\n",
        "      self.choose_set = choose_set\n",
        "\n",
        "      if choose_set == 'affwild2':\n",
        "        pkl_path = val_df_path\n",
        "      else:\n",
        "        pkl_path = val_df_nt_path\n",
        "\n",
        "    self.emotion_frame = pd.read_pickle(pkl_path)\n",
        "    self.transform = transform\n",
        "    self.res = res\n",
        "    self.flag = flag\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.emotion_frame)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "      img_path = self.emotion_frame.iloc[index, 0]           \n",
        "      fp = os.path.join('/content/cropped_aligned_val%s' %img_path) #here the path to validation frames\n",
        "      assert os.path.exists(fp), \"Image not found at: {}\".format(fp)\n",
        "\n",
        "      val_set_face = Image.fromarray(cv2.imread(fp))\n",
        "\n",
        "      if self.res is not None:\n",
        "        val_set_face = val_set_face.resize((self.res,self.res), Image.BILINEAR) #downsamplung\n",
        "\n",
        "      y_label = self.emotion_frame['label'].values[index]\n",
        "      if self.transform:\n",
        "        val_set_face = self.transform(val_set_face)\n",
        "          \n",
        "      return val_set_face, y_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weqQ57wFDahL"
      },
      "source": [
        "#DATA TRANSFORMATION\n",
        "def subtract_mean(x):\n",
        "    mean_vector = [91.4953, 103.8827, 131.0912]\n",
        "    x *= 255.\n",
        "    x[0] -= mean_vector[0]\n",
        "    x[1] -= mean_vector[1]\n",
        "    x[2] -= mean_vector[2]\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibZ2DIMf0U25"
      },
      "source": [
        "transformed_val = transforms.Compose([\n",
        "                      transforms.Resize((224,224)),\n",
        "                      transforms.ToTensor(),\n",
        "                      transforms.Lambda(lambda x : subtract_mean(x))\n",
        "                      ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLo-A8wBDm6c"
      },
      "source": [
        "val_set = AffWild2ValSet('affwild2', transform=transformed_val, res = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3mqEtSYJi6t"
      },
      "source": [
        "#Show dataset images\n",
        "def show_images(dataset, num_image):\n",
        "  fig = plt.figure()\n",
        "\n",
        "  for i in range(len(dataset)):\n",
        "\n",
        "    faces, lab = dataset[num_image]\n",
        "\n",
        "    #ax = plt.subplot(1, 4, i+1)\n",
        "    #plt.tight_layout()\n",
        "    print(\"fac \", faces.shape)\n",
        "    faces = faces.permute(1,2,0)\n",
        "    faces = cv2.cvtColor(np.float32(faces), cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(faces)\n",
        "\n",
        "    if(i == 3):\n",
        "      plt.show()\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pve_bXgI1LzD"
      },
      "source": [
        "show_images(val_set, 40000) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByBMwXyKFvZ4"
      },
      "source": [
        "#DATA GENERATORS \n",
        "validation_generator = DataLoader(val_set, batch_size = 32, num_workers = 8,  pin_memory=True, drop_last=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR69TR9gHBRE"
      },
      "source": [
        "def metrics(lab, pred):\n",
        "  lab_array = [t.numpy() for t in lab]\n",
        "  pred_array = [t.numpy() for t in pred]\n",
        "\n",
        "  pred_array = np.concatenate(pred_array, axis=0 )\n",
        "  lab_array = np.concatenate(lab_array, axis=0)\n",
        "\n",
        "  F1_score = sm.f1_score(lab_array, pred_array, average='macro', zero_division=1)\n",
        "  classes_score = sm.f1_score(lab_array, pred_array, average=None, zero_division=1)\n",
        "  print(\"Acc classes \", classes_score)\n",
        "  accuracy = sm.accuracy_score(lab_array, pred_array)\n",
        "  confusion_matrix = sm.confusion_matrix(lab_array, pred_array)\n",
        "  \n",
        "  return accuracy, F1_score, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr_MfisZHDW5"
      },
      "source": [
        "#STATISTIC COMPETITION\n",
        "def stat_comp(F1_score, accuracy):\n",
        "  stat = (0.33*accuracy) + (0.67*F1_score)\n",
        "  return stat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTQVjF2HInC"
      },
      "source": [
        "def evaluate(model):\n",
        "\n",
        "  running_val_loss = 0.0\n",
        "  total = 0\n",
        "\n",
        "  pred = []\n",
        "  lab = []\n",
        "\n",
        "  model.eval()\n",
        "  print(\"Enter Evaluation. Is Training?\", model.training)\n",
        "  with torch.no_grad():\n",
        "    for j, (data) in enumerate(progress_bar(validation_generator)):\n",
        "\n",
        "      faces_val, labels_val = data\n",
        "      faces_val = faces_val.to(device)\n",
        "      labels_val = labels_val.to(device)\n",
        "\n",
        "      _, outputs_val = model(faces_val)\n",
        "      _, preds_val = torch.max(outputs_val.data, 1)\n",
        "\n",
        "      \n",
        "      pred.append(preds_val.cpu())\n",
        "      lab.append(labels_val.cpu())\n",
        "      \n",
        "      total += labels_val.size(0)\n",
        "          \n",
        "  iteration_val_acc, F1_score, cm = metrics(lab, pred)\n",
        "              \n",
        "  return iteration_val_acc, F1_score, cm, pred, lab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6mig6BQInu9"
      },
      "source": [
        "iteration_val_acc, F1_score, cm, pred, lab = evaluate(model)\n",
        "final_stat = stat_comp(F1_score, iteration_val_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTsVdGvZAIaY"
      },
      "source": [
        "print('_________________________________________________________')\n",
        "print('Validation Acc: {:.2f}'.format(iteration_val_acc))\n",
        "print('F1_Score : {:.4f}'.format(F1_score))\n",
        "print('Final statistics: {:.4f}'.format(final_stat))\n",
        "print('_________________________________________________________')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmRZKw6G4ysO"
      },
      "source": [
        "y_true = [t.numpy() for t in lab]\n",
        "y_true = np.concatenate(y_true, axis=0 )\n",
        "\n",
        "y_pred = [t.numpy() for t in pred]\n",
        "y_pred = np.concatenate(y_pred, axis=0 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VFzXGGneryN"
      },
      "source": [
        "columns = [\"Neutral\", \"Anger\", \"Disgust\", \"Fear\", \"Happiness\", \"Sadness\", \"Surprise\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGcnDLj_qeLx"
      },
      "source": [
        "columns = [\"Neutral\", \"Positive\", \"Negative\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVE9dXSY4_4p"
      },
      "source": [
        "#plot confusion matrix\n",
        "confplot.plot_confusion_matrix_from_data(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    columns,\n",
        "    outputfile = \"/content/cm_112.png\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}